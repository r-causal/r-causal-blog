[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Visual Diagnostic Tools for Causal Inference\n\n\n\n\n\n\n\nhalfmoon\n\n\nbalance\n\n\nheterogeneous treatment effects\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nLucy D’Agostino McGowan\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing halfmoon\n\n\n\n\n\n\n\nhalfmoon\n\n\nbalance\n\n\npackages\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nMalcolm Barrett\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The r-causal organization is run by Malcolm Barrett, Lucy D’Agostino McGowan, and Travis Gerke, the authors of Causal Inference in R."
  },
  {
    "objectID": "courses/nyr-2023/index.html",
    "href": "courses/nyr-2023/index.html",
    "title": "NYR Conference: July 13-14",
    "section": "",
    "text": "Join us for a two-day workshop at the New York R conference! Available in-person and virtual."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html",
    "href": "posts/introducing-halfmoon/index.html",
    "title": "Introducing halfmoon",
    "section": "",
    "text": "We’re thrilled to announce the initial release of the halfmoon package to CRAN! halfmoon is a toolkit to assess balance in propensity-based models."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#getting-started-with-halfmoon",
    "href": "posts/introducing-halfmoon/index.html#getting-started-with-halfmoon",
    "title": "Introducing halfmoon",
    "section": "Getting started with halfmoon",
    "text": "Getting started with halfmoon\nhalfmoon is a toolkit for assessing balance in propensity score models. Additionally, it can help build your intuition for which populations various weighting and matching strategies are working. Let’s explore some of the things halfmoon can help with.\n\n# install.packages(\"halfmoon\")\nlibrary(halfmoon)\n\nLet’s take a look at an example using the built-in dataset, nhefs_weights. nhefs_weights is an extension of the nhefs dataset that includes a variety of propensity-score weights for the causal question: “Does quitting smoking increase weight?” You can find the data for this question in the causaldata package."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#population-level-balance",
    "href": "posts/introducing-halfmoon/index.html#population-level-balance",
    "title": "Introducing halfmoon",
    "section": "Population-level balance",
    "text": "Population-level balance\nThe primary tool in halfmoon for assessing balance at the population level is geom_mirrored_histogram().\nHere’s the original, unweighted sample using geom_mirrored_histogram(). The histogram on top is the exposed population, those who quit smoking. The histogram on the bottom is the unexposed population, those who did not quit smoking. While there is a lot of overlap, the two groups are slightly different.\n\nlibrary(ggplot2)\nlibrary(ggokabeito)\n\nggplot(nhefs_weights, aes(.fitted)) +\n  geom_mirror_histogram(\n    aes(group = qsmk, fill = qsmk),\n    bins = 50\n  ) +\n  scale_fill_okabe_ito()\n\n\n\n\nLet’s take a look at the same population weighted using Average Treatment Effect (ATE) weights:\n\nggplot(nhefs_weights, aes(.fitted)) +\n  # plot the original distribution in dark grey\n  geom_mirror_histogram(\n    aes(group = qsmk),\n    bins = 50\n  ) +\n  geom_mirror_histogram(\n    aes(fill = qsmk, weight = w_ate),\n    bins = 50,\n    alpha = 0.5\n  ) + scale_y_continuous(labels = abs) +\n  scale_fill_okabe_ito()\n\n\n\n\nBoth groups are upweighted to be more similar.\nWith Average Treatment Effect among the Treated (ATT) weights, the untreated group is downweighted to be more similar to the treated group:\n\nggplot(nhefs_weights, aes(.fitted)) +\n  geom_mirror_histogram(\n    aes(group = qsmk),\n    bins = 50\n  ) +\n  geom_mirror_histogram(\n    aes(fill = qsmk, weight = w_att),\n    bins = 50,\n    alpha = 0.5\n  ) + scale_y_continuous(labels = abs) +\n  scale_fill_okabe_ito()\n\n\n\n\nMirrored histograms are helpful for the dual purpose of understanding how similar the weighted populations are and precisely the population you’re analyzing."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#variable-level-balance",
    "href": "posts/introducing-halfmoon/index.html#variable-level-balance",
    "title": "Introducing halfmoon",
    "section": "Variable-level balance",
    "text": "Variable-level balance\nAnother perspective on balance is whether or not the distribution of confounders is similar between groups of the exposed. The propensity score model fit for these weights was:\n\nlibrary(causaldata)\npropensity_model &lt;- glm(\n  qsmk ~ sex +\n    race + age + I(age^2) + education +\n    smokeintensity + I(smokeintensity^2) +\n    smokeyrs + I(smokeyrs^2) + exercise + active +\n    wt71 + I(wt71^2),\n  family = binomial(),\n  # these data are loaded with the causaldata package\n  data = nhefs_complete\n)\n\nOne way to assess if we achieved balance within the confounding variables is by calculating the standardized mean difference (SMD) of the confounder between exposure groups. The closer the SMD is to 0, the more balanced the groups are on average. A common rule of thumb is to have the SMD be less than 0.11.\nLet’s calculate the SMDs for each variable using the different weights in nhefs_weights. halfmoon’s tidy_smd() creates a dataset with the SMDs for each confounder, and geom_love() visualizes the relationship.\n\nplot_df &lt;- tidy_smd(\n  nhefs_weights,\n  race:active,\n  .group = qsmk,\n  .wts = starts_with(\"w_\")\n)\n\nggplot(\n  plot_df,\n  aes(\n    x = abs(smd),\n    y = variable,\n    group = method,\n    color = method\n  )\n) +\n  geom_love() +\n  scale_color_okabe_ito()\n\n\n\n\nThis is called a Love plot, and you can use the love_plot() wrapper function to achieve the same goal:\n\nlove_plot(plot_df) +\n  scale_color_okabe_ito()\n\n\n\n\nOne downside to SMD plots is that they only give you information about one statistic that focuses on the center of the variable. For a binary or categorical variable, that’s usually enough. However, a continuous variable could be balanced in the mean but unbalanced in the tails.\nLet’s look at smokeyrs, a continuish2 variable that represents the smoke-years a participant had before quitting smoking. We’ll use the empirical cumulative distribution function (ECDF) to compare the differences between exposure groups across the range of smokeyrs.\n\nggplot(\n  nhefs_weights,\n  aes(x = smokeyrs, color = qsmk)\n) +\n  geom_ecdf() +\n  xlab(\"Smoking Years\") +\n  ylab(\"Proportion &lt;= x\") +\n  scale_color_okabe_ito()\n\n\n\n\nNow, let’s take a look with the ATE weight.\n\nggplot(\n  nhefs_weights,\n  aes(x = smokeyrs, color = qsmk)\n) +\n  geom_ecdf(aes(weights = w_ato)) +\n  xlab(\"Smoking Years\") +\n  ylab(\"Proportion &lt;= x\") +\n  scale_color_okabe_ito()\n\n\n\n\nThe balance is much better."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#matching",
    "href": "posts/introducing-halfmoon/index.html#matching",
    "title": "Introducing halfmoon",
    "section": "Matching",
    "text": "Matching\nThe examples thus far have used propensity score weights. We can also use the same techniques by treating matching as an extreme case of weighting where the weight for an observation is either 1 (the observation stays in the dataset) or 0 (the observation is removed from the dataset).\nhalfmoon’s bind_matches() facilitates the comparison of many matched datasets by creating a dataset with these weights for each model.\nConsider these two objects from the MatchIt documentation:\n\nlibrary(MatchIt)\n# Default: 1:1 NN PS matching w/o replacement\nm.out1 &lt;- matchit(treat ~ age + educ + race + nodegree +\n                   married + re74 + re75, data = lalonde)\n\n# 1:1 NN Mahalanobis distance matching w/ replacement and\n# exact matching on married and race\nm.out2 &lt;- matchit(treat ~ age + educ + race + nodegree +\n                   married + re74 + re75, data = lalonde,\n                   distance = \"mahalanobis\", replace = TRUE,\n                  exact = ~ married + race)\n\nbind_matches() creates a dataset with the original data plus the matching indicator that we’ll use as weights:\n\nmatches &lt;- bind_matches(lalonde, m.out1, m.out2)\nhead(matches)\n\n     treat age educ   race married nodegree re74 re75       re78 m.out1 m.out2\nNSW1     1  37   11  black       1        1    0    0  9930.0460      1      1\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940      1      1\nNSW3     1  30   12  black       0        0    0    0 24909.4500      1      1\nNSW4     1  27   11  black       0        1    0    0  7506.1460      1      1\nNSW5     1  33    8  black       0        1    0    0   289.7899      1      1\nNSW6     1  22    9  black       0        1    0    0  4056.4940      1      1\n\n\nNow that we have variables we can use as weights, we can use the same techniques as with propensity score weighting:\n\nmany_matched_smds &lt;- tidy_smd(\n  matches,\n  c(age, educ, race, nodegree, married, re74, re75), \n  .group = treat, \n  .wts = c(m.out1, m.out2)\n) \n\nlove_plot(many_matched_smds) +\n  scale_color_okabe_ito()\n\n\n\n\n\n# use the distance as the propensity score\nmatches$ps &lt;- m.out1$distance\n\nggplot(matches, aes(ps)) +\n    geom_mirror_histogram(\n        aes(group = factor(treat)),\n        bins = 50\n    ) +\n    geom_mirror_histogram(\n        aes(fill = factor(treat), weight = m.out1),\n        bins = 50,\n        alpha = 0.5\n    ) + \n  scale_y_continuous(labels = abs) +\n  scale_fill_okabe_ito()"
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#learn-more-in-the-book",
    "href": "posts/introducing-halfmoon/index.html#learn-more-in-the-book",
    "title": "Introducing halfmoon",
    "section": "Learn more in the book",
    "text": "Learn more in the book\nTo see an applied example of a causal analysis using halfmoon, check out the second chapter of Causal Inference in R."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#other-techniques",
    "href": "posts/introducing-halfmoon/index.html#other-techniques",
    "title": "Introducing halfmoon",
    "section": "Other techniques",
    "text": "Other techniques\nAnother way to assess the population created by weighting and matching is to use summary tables. We worked closely with the authors of gtsummary to support weighted tables. gtsummary is an incredible package for making easy, beautiful tables in R, and we highly recommend it.\nFor an example of how weighted tables can help you understand the population under analysis, check out the chapter on causal estimands in Causal Inference in R."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#future-work",
    "href": "posts/introducing-halfmoon/index.html#future-work",
    "title": "Introducing halfmoon",
    "section": "Future work",
    "text": "Future work\nhalfmoon is early in its lifecycle, although we have been teaching these techniques for several years. Right now, the focus is on causal questions with binary exposures. However, these techniques generalize to other exposures, and we plan to support continuous and categorical exposures fully."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#related-work",
    "href": "posts/introducing-halfmoon/index.html#related-work",
    "title": "Introducing halfmoon",
    "section": "Related work",
    "text": "Related work\nhalfmoon has similar goals to the popular cobalt package. We designed halfmoon to be more focused and modular than cobalt, but you might prefer cobalt if you work exclusively with related packages like MatchIt and WeightIt. cobalt also currently supports a broader range of balance metrics than halfmoon."
  },
  {
    "objectID": "posts/introducing-halfmoon/index.html#footnotes",
    "href": "posts/introducing-halfmoon/index.html#footnotes",
    "title": "Introducing halfmoon",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut don’t put too much faith in such quasirules.↩︎\nI call variables like this continuish because the number of years is represented as an integer. Theoretically, this concept is continuous, but because it is rounded to the year in the data, there are only 60 values in the variable.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Inference in R",
    "section": "",
    "text": "Welcome to the Causal Inference in R Blog! Here you’ll find more information about our packages, book, courses, and other information about causal inference.\nIf you’re looking for our book or workshop website, you can find them here:"
  },
  {
    "objectID": "index.html#r-packages",
    "href": "index.html#r-packages",
    "title": "Causal Inference in R",
    "section": "R Packages",
    "text": "R Packages\nWe develop opinionated R packages to make causal inference in R easier and more principled. Our packages are designed to work well with each other and in the Tidyverse. They’re also quite modular, meaning you can pick and choose the packages you like to work in a wide variety of settings. You can find the source code for these packages on our GitHub organization.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n\n=======  &gt;&gt;&gt;&gt;&gt;&gt;&gt; 60e1b67 (update hexes)"
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "Causal Inference in R",
    "section": "Latest posts",
    "text": "Latest posts\n\n\n\n\n\n\n\n\n\n\nVisual Diagnostic Tools for Causal Inference\n\n\n\n\n\n\nLucy D’Agostino McGowan\n\n\nAug 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing halfmoon\n\n\n\n\n\n\nMalcolm Barrett\n\n\nJun 2, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#upcoming-courses",
    "href": "index.html#upcoming-courses",
    "title": "Causal Inference in R",
    "section": "Upcoming courses",
    "text": "Upcoming courses\n\n\n\n\n\n\n\n\n\n\nNYR Conference: July 13-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nposit::conf(2023) Sept 17-18\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html",
    "href": "posts/visual-diagnostic-tools/index.html",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "",
    "text": "Here we are going to look at several diagnostic plots that are helpful when attempting to answer a causal question. They can be used to visualize the target population, balance, and treatment effect heterogeneity."
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#setup",
    "href": "posts/visual-diagnostic-tools/index.html#setup",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Setup",
    "text": "Setup\nI’ve simulated data to demonstrate the utility of the various plots. In each simulation, we have four pre-treatment variables: var1, var2, var3, and var4, a treatment, t, and an outcome y. I have also fit a propensity score model for each and calculated ATE, ATT, and overlap weights (unsure what these are? Check out this post on propensity score weighting). I will also create three propensity score matched cohorts, each with a different caliper.\nI use the following packages:\n\nlibrary(tidyverse)\nlibrary(propensity)\nlibrary(halfmoon)\nlibrary(MatchIt)\n\n\n\nFor brevity I’ve hidden the simulation code, but if you would like to see it to reproduce the analyses yourself, just click the Code toggle.\n\n\nCode\nset.seed(8)\nn &lt;- 1000\n\n## Main Data ----\n\nvar1 &lt;- rnorm(n, sd = 0.25)\nvar2 &lt;- rnorm(n, sd = 0.25)\nvar3 &lt;- rnorm(n, sd = 0.25)\nvar4 &lt;- rnorm(n, sd = 0.25)\ne_x &lt;- 1 / (1 + exp(-(var1 + var2 + var3 + var4)))\nt &lt;- rbinom(n, 1, e_x)\ny1 &lt;- 0.5 * (var1 + var2 + var3 + var4) + rnorm(n)\ny0 &lt;- - 0.5 * (var1 + var2 + var3 + var4) + rnorm(n)\ny_obs &lt;- t * y1 + (1 - t) * y0\ndata &lt;- data.frame(\n  y = y_obs,\n  t = factor(t), \n  var1, \n  var2,\n  var3,\n  var4\n)\n\ndata &lt;- data |&gt;\n  mutate(p = glm(t ~ var1 + var2 + var3 + var4, data = data, family = binomial) |&gt;\n           predict(type = \"response\"),\n         w_ate = wt_ate(p, t, .treated = 1),\n         w_ato = wt_ato(p, t, .treated = 1),\n         w_att = wt_att(p, t, .treated = 1)\n  ) \n\nmatch_1 &lt;- matchit(t ~ var1 + var2 + var3 + var4, data = data, caliper = 0.1)\nmatch_2 &lt;- matchit(t ~ var1 + var2 + var3 + var4, data = data, caliper = 0.01)\nmatch_3 &lt;- matchit(t ~ var1 + var2 + var3 + var4, data = data, caliper = 0.001)\nmatches &lt;- bind_matches(data, match_1, match_2, match_3)\n\n## Non-linear data ----\n\ne_x &lt;- 1 / (1 + exp(- (var1 + var2 + var3 + 2 * I(var4 &lt; -0.5) + 6 * I(var4 &gt; 0.5))))\nt &lt;- rbinom(n, 1, e_x)\n\ny1 &lt;- 1 + var2 + var2 + var3 + var4 \ny0 &lt;- var1 + var2 + var3 + var4\ny_obs &lt;- t * y1 + (1 - t) * y0\ndata_nonlinear &lt;- data.frame(\n  y = y_obs,\n  t = factor(t), \n  var1, \n  var2,\n  var3,\n  var4\n)\n\ndata_nonlinear &lt;- data_nonlinear |&gt;\n  mutate(p = glm(t ~ var1 + var2 + var3 + var4, data = data_nonlinear, family = binomial) |&gt;\n           predict(type = \"response\"),\n         w_ate = wt_ate(p, t, .treated = 1),\n         w_ato = wt_ato(p, t, .treated = 1),\n         w_att = wt_att(p, t, .treated = 1)\n  ) \n## Positivity violation data ----\n\nset.seed(2186)\nvar4 &lt;- rgamma(n, 1, 1.5)\ne_x &lt;- 1 / (1 + exp(- (var1 + var2 + var3 + var4 + 0.2 * var4^2 + 0.001 * var4^3)))\nt &lt;- rbinom(n, 1, e_x)\n\ndata_positivity &lt;- data.frame(\n  t = factor(t), \n  var1, \n  var2,\n  var3,\n  var4\n)\n\ndata_positivity &lt;- data_positivity |&gt;\n  mutate(p = glm(t ~ var1 + var2 + var3 + poly(var4, 3), data = data_positivity, family = binomial) |&gt;\n           predict(type = \"response\"),\n         w_ate = wt_ate(p, t, .treated = 1),\n         w_ato = wt_ato(p, t, .treated = 1),\n         w_att = wt_att(p, t, .treated = 1)\n  )"
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#target-population",
    "href": "posts/visual-diagnostic-tools/index.html#target-population",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Target Population",
    "text": "Target Population\nTargeting different causal estimands will yield different target populations (for a longer discussion of target populations see this post and check out this awesome pre-print by Noah Griefer and Liz Stuart. For example, if you are interested in answering a question with the treated group in mind, an estimand that estimates the average treatment effect among the treated (ATT), will be appropriate. Targeting this estimand will lead to selecting unexposed individuals who match the characterstics of the treated population (whether via matching to these individuals or upweighting them in the sample). Mirrored histograms can be a nice way to visualize the distribution of your target population after incorporating the propensity score when either matching or weighting are used. These basic plots are simply histograms of the propensity score, stratified by exposure. “Mirroring” these histograms above and below the x-axis, can make it easier to compare regions of overlap.\n\nWhat am I looking for?\n\nOverlap: What is the degree of overlap between the exposure groups?\nPositivity violations: Does everyone have a non-zero probability of each level of exposure?\nExtreme weights: Are there any extreme weights that could induce finite sample bias / extreme variance?\n\nLet’s take a look at an example. We can use the halfmoon package to create these.\n\n\nThe cobalt package is another excellent tool that can create many of these plots in R.\nBelow is the basic implementation of this mirrored histogram prior to incorporating the propensity score. On the top half of the visualization, we see the distribution of the propensity score in the treated group (blue); the bottom half displays the distribution among the controls (orange). Looking at this plot, I see good overlap (i.e. the two distributions overlap), and I do not see evidence of positivity violations.\n\nggplot(data, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\nNow let’s incorporate the propensity score. First, let’s see what this plot looks like if our target population is the whole population, meaning we are interested in estimate the ATE. I have added the following line of code to the ggplot layers below: geom_mirror_histogram(bins = 30, aes(weight = w_ate), alpha = 0.5). Now, I can see the pseudo-population that is created after implementing the propensity score weight. Notice the shape of the distributions match between the two groups (this is what the ATE weight is trying to do!). Looking at the figure below, I also can conclude that there aren’t any extreme weights.\n\nggplot(data, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = w_ate), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       fill = \"treatment\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\nThese plots can be useful as a pedagogical tool to give a sense for how the different target estimands lead to different target populations. For example, let’s see what the pseudo-population looks like after using the ATT weight. Notice in the figure below, the “weighted” pseudo-population in the treated arm exactly overlaps with the actual distribution of the treated observations – this is exactly what an ATT weight does, everyone in the treated population receives a weight of 1. Now look at the bottom half of the figure – the distribution of the propensity scores in the control group now matches that of the treated – in the regions were there are fewer treated observations, the control observations are down-weighted (where the propensity score is lower) and in the regions where there are more treated observations the control observations are up-weighted (where the propensity score is higher).\n\nggplot(data, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = w_att), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       fill = \"treatment\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\nFinally, let’s see how an overlap (ATO) weight compares. Notice in the figure below all observations appear to be down-weighted – the overlap weights are bounded by 0 and 1 (which means they have nice variance properties! There is no risk of having an extreme weight!). Also notice the shape of the distribution – it matches between the two groups.\n\nggplot(data, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = w_ato), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       fill = \"treatment\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\nI like to compare the overlap weights to the distribution after matching with a caliper, as they are both use to estimate a similar estimand. Here, I have created three matched cohorts, each with an increasingly smaller caliper. We can think of matching as an extreme form of weighting, where the observation will receive a weight of 1 if they are in the cohort and 0 otherwise. Here, I have created a dataset called matches that has three columns with these indiciators match_1, match_2, and match_3 (you can see the code above by clicking the Code toggle in the Setup section).\n\n\nPropensity score matching with a caliper means that you only consider matches within a pre-specified distance of each other. Smaller calipers will result in fewer matches.\n\n\nCode\nggplot(matches, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = match_1), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\nCode\nggplot(matches, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = match_2), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\nCode\nggplot(matches, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30, fill = \"grey\") + \n  geom_mirror_histogram(bins = 30, aes(weight = match_3), alpha = 0.5) + \n  annotate(\"label\", 0.5, -10, label = \"control\") +\n  annotate(\"label\", 0.5, 10, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       y = \"count\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\nFor demonstration purposes, let’s see what one of these plots looks like in a dataset that doesn’t have perfect overlap. Whoa! Look at that weight in the figure below. This is an example where we see a possible positivity violation (some observations of propensity scores very close to 1) and extreme weights (check out that control with a weight &gt; 500!).\n\nggplot(data_positivity, aes(p, fill = t, group = t)) +\n  geom_mirror_histogram(bins = 30) + \n  geom_mirror_histogram(bins = 30, aes(weight = w_ate), alpha = 0.5) +\n  annotate(\"label\", 0.6, -20, label = \"control\") +\n  annotate(\"label\", 0.6, 20, label = \"treated\") +\n  scale_y_continuous(labels = abs) +\n  labs(x = \"propensity score\",\n       y = \"count\") + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#balance-visualization",
    "href": "posts/visual-diagnostic-tools/index.html#balance-visualization",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Balance visualization",
    "text": "Balance visualization\nOk, once we’ve checked out the target population, we can see how balanced the exposure groups are after incorporating the propensity score.\n\nWhat am I looking for?\n\nbalance (in the mean) between treatment groups\nbalance across the distribution (for continuous confounders)\n\n\n\nBalance in the mean\nA common way to look at balance is the standardized mean difference. This will tell us whether the (standardized) means are balanced between the treatment groups (we often target an absolute standardized mean difference less than 0.1 as a rule of thumb). We can use the tidy_smd function to calculate the standardized mean differences between the exposure groups in our example dataset. Let’s see how they compare across the matched datasets.\n\nmatches_smd &lt;- tidy_smd(\n  matches,\n  var1:var4,\n  .group = t,\n  .wts = c(match_1, match_2, match_3)\n)\n\nA nice way to visualize these is a Love Plot (named for Thomas Love, who was one of the first folks to use them). In the halfmoon package there is a geom_love that will help create this as a layer in a ggplot, or you can use the shorthand love_plot. Below we can see that all three matched sets achieve balance with respect to demonstrating standardized mean differences across all pre-treatment variables less than the rule of thumb (0.1). Each of the different “matches” denote a different caliper (from largest: match_1 to smallest: match_3). We see here that using a smaller caliper seems to help balance var2 at the expense of var4 and var1 compared to the larger calipers.\n\nggplot(matches_smd, aes(abs(smd), variable, group = method, color = method)) + \n  geom_love() + \n  labs(x = \"Absolute standardized mean difference\")\n\n\n\n\nLet’s look at another dataset. I have simulated data I am calling data_nonlinear. Let’s check out the Love Plot for this data. This time I will use our propensity score weights.\n\nweighted_smd &lt;- tidy_smd(\n  data_nonlinear,\n  var1:var4,\n  .group = t,\n  .wts = c(w_ate, w_att, w_ato)\n)\n\nggplot(weighted_smd, aes(x = abs(smd), y = variable, group = method, color = method)) + \n  geom_love() +   \n  labs(x = \"Absolute standardized mean difference\")\n\n\n\n\nGreat! Looks like any of our weighting choices will achieve balance on the mean. Check out the green line (the overlap weights) – the standardized mean differences are exactly 0! This is a feature of this weight, if the propensity score is fit using logistic regression, any variables included in the model will be perfectly balanced on the mean – COOL! BUT as you may have guessed by the name of this dataset, the mean does not tell the whole story. These variables are continuous, so being balanced on the mean does not guarantee that the whole distribution is balanced. To examine the distribution of a variable across treatment groups, we can use an empirical cumulative distribution plot."
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#balance-across-the-distribution",
    "href": "posts/visual-diagnostic-tools/index.html#balance-across-the-distribution",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Balance across the distribution",
    "text": "Balance across the distribution\nThe geom_ecdf function in the halfmoon package allows for you to visualize weighted empirical CDFs. Let’s first look at the unweighted eCDF for var4. We are going to plot the range of var4 values on the x-axis and the proportion of var4 values that are less than the given x-value on the y-axis (the empirical CDF), stratified by treatment. Looking at the figure below, we see gaps between the lines (meaning the two lines to not overlap, implying that the distributions differ).\n\nggplot(data_nonlinear, aes(x = var4, group = t, color = t)) + \n  geom_ecdf() + \n  labs(y = \"Proportion &lt;= x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nNow we can compare this to the weighted eCDF to see if the propensity score weighting improves the balance – I’ll use the overlap weights for demonstration purposes. Hmm. We can see in the plot below that the lines cross (they are balanced on the mean, we knew that from the Love Plot), but there are still pretty large gaps across other portions of the distribution. This suggests that there are some non-linear effects that the propensity score is failing to capture.\n\nggplot(data_nonlinear, aes(x = var4, group = t, color = t)) + \n  geom_ecdf(aes(weights = w_ato)) + \n  labs(y = \"Proportion &lt;= x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nLet’s try to refit our propensity score model with a spline on the var4 variable, and then recreate our plot.\n\ndata_nonlinear &lt;- data_nonlinear |&gt;\n  mutate(p = glm(t == 1 ~ var1 + var2 + var3 + splines::ns(var4, 4), \n                 data = data_nonlinear) |&gt;\n           predict(type = \"response\"),\n         w_ato = wt_ato(p, t, .treated = 1)) \n\nggplot(data_nonlinear, aes(x = var4, group = t, color = t)) + \n  geom_ecdf(aes(weights = w_ato)) + \n  labs(y = \"Proportion &lt;= x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nMuch better!"
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#heterogeneous-treatment-effect",
    "href": "posts/visual-diagnostic-tools/index.html#heterogeneous-treatment-effect",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Heterogeneous treatment effect",
    "text": "Heterogeneous treatment effect\nHere is the last visual! This is a quick plot that can help explore possible treatment heterogeneity.\n\nWhat am I looking for?\n\nDifferences in the treatment effect across the covariate space\n\nIn this example dataset, the average treatment effect is 0. Let’s show that. There are lots of ways to estimate this, for example, we can use the ATE weights.\n\nlm(y ~ t, data = data, weight = w_ate)\n\n\nCall:\nlm(formula = y ~ t, data = data, weights = w_ate)\n\nCoefficients:\n(Intercept)           t1  \n   -0.02095     -0.05364  \n\n\nAwesome! Now let’s create a plot to see if this effect is constant across the covariate space. One way to summarize the “covariate space” is the propensity score! This simple plot has the propensity score on the x-axis and the outcome on the y-axis. We then stratify by the treatment and look at a smoothed line in both groups.\n\nggplot(data, aes(x = p, y = y, color = t)) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"loess\", formula = \"y ~ x\") + \n  labs(x = \"Propensity score\",\n       color = \"Treated\")\n\n\n\n\nThe lines cross! This indicates that there is treatment effect heterogeneity (in this particular case, when the propensity score is greater than 0.5, there is a positive treatment effect, and when less than 0.5 there is a negative treatment effect).\n\n\nYou can find a longer post about these plots here.\nJust to see what it looks like when there is not a heterogeneous treatment effect, let’s check out the data_nonlinear dataset (where I simulated a constant effect). Notice below the lines don’t cross, the width between them is constant across the covariate space.\n\nggplot(data_nonlinear, aes(x = p, y = y, color = t)) +\n  geom_point(alpha = 0.5) + \n  geom_smooth(method = \"lm\", formula = \"y ~ x\")"
  },
  {
    "objectID": "posts/visual-diagnostic-tools/index.html#wrap-up",
    "href": "posts/visual-diagnostic-tools/index.html#wrap-up",
    "title": "Visual Diagnostic Tools for Causal Inference",
    "section": "Wrap up",
    "text": "Wrap up\nSo there you have it! Four visualizations to add to your tool kit when attempting to answer causal questions.\nThis post is cross-posted on Lucy’s blog, livefreeordichotomize.com"
  },
  {
    "objectID": "courses/posit-conf-2023/index.html",
    "href": "courses/posit-conf-2023/index.html",
    "title": "posit::conf(2023) Sept 17-18",
    "section": "",
    "text": "Join us for a two-day workshop at the posit::conf(2023) conference! Available in-person.\n\nTo learn more about our workshop, visit the GitHub repository containing materials you’ll learn."
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Upcoming Courses",
    "section": "",
    "text": "NYR Conference: July 13-14\n\n\n\n\n\n\n\ntwo-day workshop\n\n\nnyr\n\n\nin-person\n\n\nvirtual\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nposit::conf(2023) Sept 17-18\n\n\n\n\n\n\n\ntwo-day workshop\n\n\nposit::conf\n\n\nin-person\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]